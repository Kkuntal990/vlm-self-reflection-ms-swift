apiVersion: v1
kind: Pod
metadata:
  name: vlm-jupyter-1gpu
spec:
  restartPolicy: Never
  imagePullSecrets:
  - name: ghcr-secret
  containers:
  - name: jupyter-container
    image: ghcr.io/kkuntal990/ms-swift-qwen:latest
    command: ["jupyter", "lab", "--ip=0.0.0.0", "--no-browser", "--allow-root", "--NotebookApp.token=selfimprove"]

    resources:
      limits:
        nvidia.com/a100: "1"
        memory: "16Gi"
        cpu: "2"
      requests:
        nvidia.com/a100: "1"
        memory: "16Gi"
        cpu: "2"


    volumeMounts:
      - name: cache-volume
        mountPath: /cache
      - name: outputs-volume
        mountPath: /outputs

    env:
    # HuggingFace token (optional for public models)
    - name: HF_TOKEN
      valueFrom:
        secretKeyRef:
          name: hf-token
          key: token
          optional: true

    # Cache directories (from scripts/env.sh)
    - name: HF_HOME
      value: "/cache/hf"
    - name: TRANSFORMERS_CACHE
      value: "/cache/hf/transformers"
    - name: HF_DATASETS_CACHE
      value: "/cache/hf/datasets"
    - name: TORCH_HOME
      value: "/cache/torch"
    - name: PIP_CACHE_DIR
      value: "/cache/pip"
    - name: OUTPUT_DIR
      value: "/outputs"

    # Model and dataset configuration
    - name: MODEL_ID
      value: "Qwen/Qwen2.5-VL-7B-Instruct"
    - name: DATASET_ID
      value: "/outputs/fire_bc_coco_only/fire_sharegpt_train.jsonl"

    # Training hyperparameters
    - name: MAX_LEN
      value: "2048"
    - name: BATCH
      value: "4"
    - name: GRAD_ACC
      value: "8"
    - name: EPOCHS
      value: "1000"
    - name: LR
      value: "2e-4"
    - name: LORA_RANK
      value: "8"
    - name: LORA_ALPHA
      value: "16"

    # Python and CUDA settings
    - name: PYTHONUNBUFFERED
      value: "1"
    - name: PYTORCH_CUDA_ALLOC_CONF
      value: "expandable_segments:True"

  tolerations:
    # Tolerate reserved nodes
    - key: nautilus.io/reservation
      operator: Exists
      effect: NoSchedule

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: nvidia.com/gpu.product
            operator: In
            values:
            - NVIDIA-A100-SXM4-80GB

  volumes:
    - name: cache-volume
      persistentVolumeClaim:
        claimName: ms-swift-cache-pvc
    - name: outputs-volume
      persistentVolumeClaim:
        claimName: ms-swift-outputs-pvc
